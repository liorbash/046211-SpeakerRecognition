# -*- coding: utf-8 -*-
"""data_loader.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F570vUaQ3oQ0rC2hnQHhIzNkC2q4SpH1
"""

from torchaudio import datasets
import torchaudio.transforms
import torchvision.transforms
from torch.utils.data import DataLoader, Dataset
from torch.utils.data.sampler import SubsetRandomSampler
import numpy as np
import torch
from sklearn.preprocessing import MinMaxScaler

# converting audio to melspectograms
import os
import matplotlib.pyplot as plt
#for loading and visualizing audio files
import librosa
import librosa.display

class VoxCaleb1MelSpecDataset(Dataset):
    def __init__(self, data_dir, subset, input_size, sr=16000, do_log=False, download=False):
        """
        Args:
            csv_file (string): Path to the csv file with annotations.
            data_dir (string): Directory with all the audio files.
            sr (int): audio files' sample rate
            input size (int)
        """
        self.data_dir = data_dir
        #self.transform = transform  
        self.input_size = input_size  
        self.do_log = do_log
        if subset == 'val':
          subset = 'dev'
        self.dataset = datasets.VoxCeleb1Identification(root=self.data_dir, subset=subset, download=download)
        self.idx = {'waveform': 0, 'sr': 1, 'speaker_id': 2, 'path_wav': 3}
        return

    def __len__(self):
        return len(self.dataset)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        sample = self.dataset[idx]

        # Transforms
        ## define transforms
        transform1 = torchaudio.transforms.MelSpectrogram(sample_rate=16000, n_fft=512, win_length=400, hop_length=160, f_min=0.0, f_max=8000, pad=0, n_mels=40)
        scaler = MinMaxScaler()
        transforms2 = torch.nn.Sequential(
          torchvision.transforms.Normalize([0.485], [0.229]),
          torchvision.transforms.Resize((self.input_size, self.input_size))
        )
        sample = list(sample)
        ## transform the audio samples
        sample[self.idx['waveform']] = transform1(sample[self.idx['waveform']])
        sample[self.idx['waveform']][0,:,:] = torch.Tensor(scaler.fit_transform(sample[self.idx['waveform']][0,:,:]))
        sample[self.idx['waveform']] = transforms2(sample[self.idx['waveform']])
        sample = tuple(sample)
        
        # RGB
        image = torch.cat((sample[self.idx['waveform']], sample[self.idx['waveform']], sample[self.idx['waveform']]), 0)
        #image = sample[self.idx['waveform']]
        # labels start at 0 instead of 1
        label = sample[self.idx['speaker_id']] - 1
        return image, label

def get_datasets(input_size, dataset_dir='.', download=False):
  train_dataset = VoxCaleb1MelSpecDataset(dataset_dir, 'train', input_size=input_size, download=download)
  validation_dataset = VoxCaleb1MelSpecDataset(dataset_dir, 'dev', input_size=input_size, download=download)
  test_dataset = VoxCaleb1MelSpecDataset(dataset_dir, 'test', input_size=input_size, download=download)
  return {'train': train_dataset, 'val': validation_dataset, 'test': test_dataset}

def get_dataloader(dataset, batch_size, num_workers=2):
  data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,
                                                      num_workers=num_workers)
        
  return data_loader

def get_dataloaders(dataset_list, train_batch_size, num_workers=2):
    train_dataloader = get_dataloader(dataset_list['train'], train_batch_size, num_workers=num_workers)
    validation_dataloader = get_dataloader(dataset_list['val'], len(dataset_list['val']), num_workers=num_workers)
    test_dataloader = get_dataloader(dataset_list['test'], len(dataset_list['test']), num_workers=num_workers)
    return {'train': train_dataloader, 'val': validation_dataloader, 'test': test_dataloader}

def plot_batch(dataset, batch_size, num_workers):
  loader = get_dataloader(dataset, batch_size=batch_size, num_workers=num_workers)
  dataiter = iter(loader)
  data = next(dataiter)
  images = data[0]
  labels = data[2]

  fig, axes = plt.subplots(1, len(images), figsize=(12,2.5))
  for idx, image in enumerate(images):
      axes[idx].imshow(image[0,:,:])
      axes[idx].set_title(labels[idx])
      axes[idx].set_xticks([])
      axes[idx].set_yticks([])