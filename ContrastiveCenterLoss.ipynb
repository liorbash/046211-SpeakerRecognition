{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "S7M0WJzu3OKy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import copy\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "from Trainer import Trainer, initialize_resnet_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "\n",
        "set_seed(0)"
      ],
      "metadata": {
        "id": "ixsDlKnY5FfC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device - cpu or gpu?\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "9ojC-LVa5KZY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDFq0JffFQDJ",
        "outputId": "eab8cb1c-f96d-4c67-e68e-cde4274d2b9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveCenterLoss(nn.Module):\n",
        "    def __init__(self, dim_hidden, num_classes, device, lambda_c=1.0):\n",
        "        super(ContrastiveCenterLoss, self).__init__()\n",
        "        self.dim_hidden = dim_hidden\n",
        "        self.num_classes = num_classes\n",
        "        self.lambda_c = lambda_c\n",
        "        self.centers = nn.Parameter(torch.randn(num_classes, dim_hidden))\n",
        "        self.device = device\n",
        "        self.data = {'intra_distances': [], 'inter_distances': [], 'loss': []}\n",
        "        \n",
        "    def forward(self, y, hidden):\n",
        "        batch_size = hidden.size()[0]\n",
        "        expanded_centers = self.centers.expand(batch_size, -1, -1)\n",
        "        expanded_centers = expanded_centers.to(self.device)\n",
        "        hidden = hidden.view(hidden.size(0), -1)\n",
        "        expanded_hidden = hidden.expand(self.num_classes, -1, -1).transpose(1, 0)\n",
        "        distance_centers = (expanded_hidden - expanded_centers).pow(2).sum(dim=-1)\n",
        "        distances_same = distance_centers.gather(1, y.unsqueeze(1))\n",
        "        intra_distances = distances_same.sum()\n",
        "        inter_distances = distance_centers.sum().sub(intra_distances)\n",
        "        epsilon = 1e-6\n",
        "        loss = (self.lambda_c / 2.0 / batch_size) * intra_distances / \\\n",
        "               (inter_distances + epsilon) / 0.1\n",
        "        # save data\n",
        "        self.data['intra_distances'].append(intra_distances.data)\n",
        "        self.data['inter_distances'].append(inter_distances.data)\n",
        "        self.data['loss'].append(loss.data)\n",
        "        return loss"
      ],
      "metadata": {
        "id": "W_iRCgsk3Z2l"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extract = False # fine-tuning\n",
        "num_classes = 200\n",
        "\n",
        "resnet18_model_fine_tuning, input_size = initialize_resnet_model(num_classes=num_classes, feature_extract=feature_extract, use_pretrained=True)\n",
        "resnet18_model_fine_tuning = resnet18_model_fine_tuning.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "# fine-tuning we will be updating all parameters. However, if we are\n",
        "# doing feature extract method, we will only update the parameters\n",
        "# that we have just initialized, i.e. the parameters with requires_grad\n",
        "# is True.\n",
        "params_to_update = resnet18_model_fine_tuning.parameters()\n",
        "if feature_extract:\n",
        "  params_to_update = []\n",
        "  for name,param in resnet18_model_fine_tuning.named_parameters():\n",
        "    if param.requires_grad == True:\n",
        "      params_to_update.append(param)\n",
        "\n",
        "\n",
        "# Losses\n",
        "CE_loss = nn.CrossEntropyLoss()                       # <--- Cross Entropy Loss    \n",
        "center_loss = ContrastiveCenterLoss(dim_hidden=512,   # <--- Contrastive Center Loss\n",
        "                                    num_classes=num_classes,\n",
        "                                    device=device,\n",
        "                                    lambda_c=1.0)\n",
        "CE_loss, center_loss = CE_loss, center_loss\n",
        "criterion = [CE_loss, center_loss]\n",
        "\n",
        "# Optimizers & Scheduler\n",
        "optimizer_nn = optim.Adam(resnet18_model_fine_tuning.parameters(), lr=1e-6, betas=(0.9, 0.98), eps=1e-09)\n",
        "optimizer_c = optim.Adagrad(center_loss.parameters(), lr=0.001)         # <--- Optimizer for Contrastive Center Loss\n",
        "optimizer = [optimizer_nn, optimizer_c]\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_nn, step_size=7, gamma=0.1)\n",
        "\n",
        "resnet18_model_fine_tuning_trainer = Trainer(resnet18_model_fine_tuning, device, input_size, criterion, \n",
        "                                             optimizer, exp_lr_scheduler, batch_size=64, num_epochs=30, num_workers=2, \n",
        "                                             dataset_dir='./drive/MyDrive/VoxCeleb1')\n"
      ],
      "metadata": {
        "id": "vAChuErP3nBY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18_model_fine_tuning_trainer.train_model_ccl('train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qmf8JMmEcuY",
        "outputId": "383b8ad4-598d-4c2e-f523-6cc6cdaf8be0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 5.4323 Acc: 0.0039\n",
            "val Loss: 5.4447 Acc: 0.0028\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 5.3524 Acc: 0.0059\n",
            "val Loss: 5.4227 Acc: 0.0046\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 5.2788 Acc: 0.0110\n",
            "val Loss: 5.3978 Acc: 0.0055\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 5.2074 Acc: 0.0250\n",
            "val Loss: 5.3809 Acc: 0.0101\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 5.1386 Acc: 0.0425\n",
            "val Loss: 5.3595 Acc: 0.0129\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 5.0704 Acc: 0.0580\n",
            "val Loss: 5.3466 Acc: 0.0148\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 5.0014 Acc: 0.0688\n",
            "val Loss: 5.3285 Acc: 0.0175\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 4.9577 Acc: 0.0731\n",
            "val Loss: 5.3294 Acc: 0.0175\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 4.9522 Acc: 0.0740\n",
            "val Loss: 5.3293 Acc: 0.0194\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 4.9438 Acc: 0.0744\n",
            "val Loss: 5.3226 Acc: 0.0175\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 4.9368 Acc: 0.0746\n",
            "val Loss: 5.3254 Acc: 0.0175\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EgK3MV1KpOce"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}